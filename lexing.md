---
tags: dev, compiler
---

Lexing, lexical analysis eller tokenization är en process där man konverterar en sekvens av tecken till en sekvens av tokens (strängar med en definierad betydelse). Ett program som utför lexing kallas ofta för en _lexer_, _tokenizer_ eller _scanner_ (även fast _scanner_ också är term som beskriver första steget i en _lexer_). En _lexer_ kombineras ofta med en _parser_ och används för att analysera syntaxen av källkod, en webbsida eller liknande.

Exempel på en lexer finns på
https://github.com/PatrikOlin/monkey_interpreter/blob/master/lexer/lexer.go
